---
title: "NFL Assignment"
#author: "ANONYMOUS (Keep it this way)"
date: "`r Sys.Date()`"
output: pdf_document
---

```{r setup, include=FALSE, warning = FALSE, message = FALSE}
library( tidyverse )
library(dplyr)
library(tidyr)
knitr::opts_chunk$set(echo = TRUE)

#Read in the data, note that we define several values in the original dataset as NA
nfl <- read_csv( "data/NFL-Census-Data-9.2.2013_clean.csv", 
                 na = c("NA","N/A","", "n/a", "#VALUE!") )
head (nfl)
```


# ~~~ Data Exploration ~~~

# 1. Find the highest and lowest salary in the dataset.

```{r}
# some code

max(nfl$Salary, na.rm = TRUE)
min(nfl$Salary, na.rm = TRUE)
# 2. Print the college and state for the five best paid players of the San Francisco 49ers
nfl %>% 
    filter( Team == "SF" )  %>% 
    arrange( desc( Salary ) ) %>% 
    select( College, State ) %>% 
    head(5)
```


# 3. Calculate the mean salary and number of players in the dataset for each position

Arrange your results from highest to lowest mean salary.

Hint: You might want some of the following code. You should also use the `group_by() + summarise()` combo.  Also use `summarise( n = n() )` to make a count of the number of records.

```{r}
clean.dat <- nfl %>% 
    filter( !is.na( Salary ) )
clean.dat %>%
    group_by( Position ) %>%
    summarise( mean_salary = mean( Salary ), number_of_players = n() ) %>%
    arrange( desc( mean_salary ) )
    
```


# 4. Determine if taller players get paid more

Use linear regression to answer this question.
For an overview of linear regression in R, see the course video and materials posted on Canvas.

Sometimes measures such as salary have such a skew that the outliers cause real problems.
For doing this question, you migth first try log transforming Salary via a mutate command to make `logSal = log( Salary )`, and then fitting your model on that space.

```{r}
# some code
clean.dat <- nfl %>% 
    filter( !is.na( Salary ) )
clean.dat <- clean.dat %>%
    mutate( logSal = log( Salary ) )

# I couldn't generate a plot with a line, so I asked ChatGPT why that was happening... and it suggested investigating if Height and logSal are numeric. Height is a string. So now I have to convert it to numeric.
# clean.dat$Height <- as.numeric(clean.dat$Height)

# the line above actually didn't convert the height to numeric, so I'll convert it from feet and inches to centimeters. I asked ChatGPT how to do that, and it suggested using separate() to split the height into feet and inches, and then doing some math to convert it to centimeters.

clean.dat2 <- clean.dat %>% 
  mutate(Height_clean = gsub('"', "", Height)) %>% 
  separate(Height_clean, into = c("feet", "inches"), sep = "'", convert = TRUE) %>%
  mutate(feet = as.numeric(feet), inches = as.numeric(inches)) %>%
  mutate(Height_cm = (feet * 12 + inches) * 2.54)


head(clean.dat2)

# I got a warning saying ! NAs introduced by coercion, so I filtered the NA info from Height_cm.


clean.dat2 <- clean.dat2 %>% 
    filter( !is.na( Height_cm ) )

# finally generate the plot again, and see if there's a relationship between height and log salary.

ggplot( clean.dat2, mapping = aes( x = Height_cm, y = logSal ) ) +
    geom_point() +
    geom_smooth( method = "lm", se = FALSE) 

# visually there's a slight positive relationship between height and log salary, but let's see what the regression says and if there's a statistically significant relationship.

model <- lm( logSal ~ Height_cm, data = clean.dat2 )
summary( model )

# the coefficient for Height_cm is positive, which suggests that taller players tend to have higher log salaries. The p-value for the coefficient is less than 0.05, which suggests that the relationship is statistically significant. However, the R-squared value is quite low, which suggests that height alone does not explain much of the variation in log salary. Should we interpret the Confidence Interval as well?


# not sure how to do this:
exp( coef( model ) )


```

Once you do, you can use `exp( coef )`, where `coef` is the coefficient from your regression, to get an interpretation of your coefficient as percent change in salary given a change in height.


# 5. Improve the linear model

What do you think about the results in (4)?  If you found differences, can you explain them by accounting for player position in your model?  In other words, what happens when you include position in your model?

```{r}
# some code
model_2 <- lm( logSal ~ Height_cm + Position, data = clean.dat2 )
summary( model_2 )


# when adding Position to the model as a control model, the coefficient for Height_cm is still positive but statistically insignificant (p-value above the threshold of 0.05), but the R-squared value has increased, which suggests that including Position in the model helps to explain more of the variation in log salary. This indicates that player position is an important factor in determining salary, and that height alone does not fully capture the differences in salary among players.


# I'd like to know which position is the reference category in the model, so I can interpret the coefficients for the other positions. To find out, I can check the levels of the Position variable.

```

Some words of discussion go here.


# 6. Print the mean weight and height for the football players, calculated for each position

You are going to have to get height cleaned up.  You might try `separate()` (see R for DS) to make feet and inches, and then do some math via `mutate()`. You could also use `substring()`. In any case, you might find `parse_number()` a useful function. Note that one foot (abbreviated as ') is equal to 12 inches (abbreviated to ").
Try asking a Large Language Model for help with this one.

```{r}
# some code
# I already cleaned up the height in the previous question, so I can just use the clean.dat2 and Height_cm dataset to calculate the mean weight and height for each position. 
clean.dat2 %>%
  group_by( Position ) %>%
  summarise( mean_weight = mean(Weight, na.rm = TRUE ), 
             mean_height_cm = mean( Height_cm, na.rm = TRUE ) ) %>%
  arrange( desc( mean_height_cm ) )

```

\newpage

# ~~~ Visualizations ~~~

## 7. Make a graph with 3 variables: X axis, Y axis, and plot point coloring, that tells a story.

**please note:** we will be deducting points for messy plots, plots with poor labeling, or plots that are hard to read.  Make sure your plots are clear and easy to understand.

```{r}
# You pick the variables.  What would be interesting?
ggplot( clean.dat2, mapping = aes( x = Height_cm, y = logSal, color = Position ) ) +
    geom_point() +
    geom_smooth( method = "lm", se = FALSE) +
    labs( x = "Height (cm)", y = "Log Salary", color = "Position" )


# your code goes here
```

**7(B)** Explain what the plot tells us.

## 8. Make a graph with 4 variables that tells a story that your first plot does not.

For the four variables, perhaps you could use X axis, Y axis, plot point coloring, and plot point size, or perhaps plot point shape or some other attribute. **Do not** use any facets yet.  Just a single plot.  Other than that constraint, you pick!

```{r}
# some code
ggplot( clean.dat2, mapping = aes( x = Height_cm, y = logSal, color = Position, size = Weight ) ) +
    geom_point() +
    geom_smooth( method = "lm", se = FALSE) +
    labs( x = "Height (cm)", y = "Log Salary", color = "Position" )


# I know this is awful! haha we should choose better ways to code the variables.
```

**8(B)** What does this plot tell us that the other plot doesn't?

## 9. When might we prefer simpler plots with fewer moving pieces to more complicated plots?

## 10. Now extend or modify your plot by making multiple plots in the same window.

You want to use either `facet_wrap()` or `facet_grid()` here.

```{r}
# some code
# to be improved, I just wanted to know the possibilities with facet_wrap

ggplot( clean.dat2, mapping = aes( x = Height_cm, y = logSal, color = Position ) ) +
    geom_point() +
    geom_smooth( method = "lm", se = FALSE) +
    labs( x = "Height (cm)", y = "Log Salary", color = "Position" ) +
    facet_wrap( ~ Position )
```

**10(B)** Compared to your prior plots, does this plot make anything easier to see?  Harder to see?


## 11. I'd like to know if taller players are paid more in some positions but not others. Make a plot to answer that question. 

```{r}
# some code (co-pilot did this one for me)
ggplot( clean.dat2, mapping = aes( x = Height_cm, y = logSal ) ) +
    geom_point() +
    geom_smooth( method = "lm", se = FALSE) +
    labs( x = "Height (cm)", y = "Log Salary" ) +
    facet_wrap( ~ Position )
```


**11(B).** What does your plot say?


\newpage

# ~~~ A touch of modeling ~~~

## 12. (2 pts) Make a predictive model (using OLS) to predict log salary using some set of other covariates and print out a summary of the model. Specify how you decided to treat missing data. 


```{r}
# some code (co-pilot + na.action = na.omit was suggested by ChatatGPT)
model_final <- lm( 
  logSal ~ Height_cm + Weight + Position + Age + Experience, 
  data = clean.dat2,
  na.action = na.omit)

dim(predict(model_final))

summary( model_final )
```

## 13. Make a plot showing predictions vs actual, and also make a residual plot. 

```{r}
# some code
clean.dat2 <- clean.dat2 %>%
  filter(complete.cases(Height_cm, Weight, Position, Age, Experience))

# the above line was suggested by chatgpt after failing to filter na in multiple varables.

ggplot( clean.dat2, aes( x = logSal, y = predict( model_final ) ) ) +
    geom_point() +
    geom_abline( slope = 1, intercept = 0, col = "red" ) +
    labs( x = "Actual Log Salary", y = "Predicted Log Salary" )

length(predict(model_final))
nrow(clean.dat2)
head(clean.dat2)
# above is a frankstein of code from me, co-pilot, and chatgpt.
```

```{r}
# 1. Clean data for the model
model_dat <- clean.dat2 %>%
  filter(complete.cases(logSal, Height_cm, Weight, Position, Age, Experience))

# 2. Fit model on *model_dat*
model_final <- lm(logSal ~ Height_cm + Weight + Position + Age + Experience,
                  data = model_dat)

# 3. Add predictions to *model_dat*
model_dat$pred <- predict(model_final)

# 4. Plot: guaranteed same rows, same order
ggplot(model_dat, aes(x = logSal, y = pred)) +
  geom_point() +
  geom_abline(slope = 1, intercept = 0, col = "red")

# above is the suggestion from chatgpt to make sure that I'm comparing the predictions to the actual values for the same set of observations, since the model is only trained on a subset of the data that has complete cases for all the variables.


# residuals plot
ggplot( clean.dat2, aes( x = predict( model_final ), y = resid( model_final ) ) ) +
    geom_point() +
    geom_hline( yintercept = 0, col = "red" ) +
    labs( x = "Predicted Log Salary", y = "Residuals" )
  
```

**13(B)** Do these plots show any problems?


## 14. How old do players get?

Make a distribution of the ages of players in the dataset, and then speculate about how long a player might be able to play in the NFL.

```{r}
# some code (co-pilot did this one for me)
clean.dat2 %>%
  filter( !is.na( Age ) ) %>%
  ggplot( aes( x = Age ) ) +
    geom_histogram( binwidth = 1, color = "white", fill = "steelblue" ) +
    labs( title = "Distribution of Player Ages", x = "Age", y = "Count" )
```

Your answer here.

**14(B).** Poke around on the internet to see what a typical age of retirement is.  How did that compare to your own assessment?


## 15. (2 pts) Use these data and your work to predict what average lifetime earnings would be for a median level pay NFL player.

```{r}
# some code
```

Be sure to explain your reasoning.


\newpage

# ~~~ Extensions ~~~

In this part of the assignment we offer two, very open ended, extensions.
They represent a reasonable amount of work, but are only worth 2 points---in other words, you can choose to do them if you want to go above and beyond, but you can still get a fine grade without doing them at all.
We will only grade at most one extension, and we will grade the first we see.

Both extensions relate to a second dataset, `Master-Player-List-2024.csv`, that you have in the data folder.

## Extension Option 1. Comparing to a more modern dataset.

How much more are players paid now, compared to 2013?
Try to account for differences in the datasets in terms of, for example, age and experience of the players in each dataset.
Write up your results using at least one visualization and some text explaining any analysis you did.



## Extension Option 2. Out of Sample Prediction

Using the 2013 data as a training set, try to predict salaries in the 2024 data with your linear model.
Then assess how well your 2013 predictions work.
One measure is the "Root Mean Square Error" (RMSE), which is defined as follows:
$$ RMSE = \sqrt{ \frac{1}{n} \sum_{i=1}^n ( y_i - \hat{y}_i )^2 } $$

where $y_i$ is the actual salary, $\hat{y}_i$ is the predicted salary, and $n$ is the number of players in the 2024 dataset.

**Hint:** You will need to do some data cleaning to get the two datasets to line up.
In particular, rename variables so they have the same names.


